{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모두딥13장 과적합 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cga29XqWrP0"
      },
      "source": [
        "# 광물 예측 \r\n",
        "\r\n",
        "## 데이터 확인 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4b_E_CqUVjT"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4L8G5VnYk9L"
      },
      "source": [
        "### 데이터 개요 파악"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cipMwzj-XxeE",
        "outputId": "a3082e4c-e777-48f6-f0c9-643d85aca730"
      },
      "source": [
        "# seed 값 설정\r\n",
        "np.random.seed(3)\r\n",
        "tf.random.set_seed(3)\r\n",
        "\r\n",
        "# 데이터 입력\r\n",
        "df = pd.read_csv('../content/drive/MyDrive/모두의 딥러닝/deeplearning/dataset/sonar.csv',header=None)\r\n",
        "\r\n",
        "print(df.info())\r\n",
        "print(df.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       208 non-null    float64\n",
            " 1   1       208 non-null    float64\n",
            " 2   2       208 non-null    float64\n",
            " 3   3       208 non-null    float64\n",
            " 4   4       208 non-null    float64\n",
            " 5   5       208 non-null    float64\n",
            " 6   6       208 non-null    float64\n",
            " 7   7       208 non-null    float64\n",
            " 8   8       208 non-null    float64\n",
            " 9   9       208 non-null    float64\n",
            " 10  10      208 non-null    float64\n",
            " 11  11      208 non-null    float64\n",
            " 12  12      208 non-null    float64\n",
            " 13  13      208 non-null    float64\n",
            " 14  14      208 non-null    float64\n",
            " 15  15      208 non-null    float64\n",
            " 16  16      208 non-null    float64\n",
            " 17  17      208 non-null    float64\n",
            " 18  18      208 non-null    float64\n",
            " 19  19      208 non-null    float64\n",
            " 20  20      208 non-null    float64\n",
            " 21  21      208 non-null    float64\n",
            " 22  22      208 non-null    float64\n",
            " 23  23      208 non-null    float64\n",
            " 24  24      208 non-null    float64\n",
            " 25  25      208 non-null    float64\n",
            " 26  26      208 non-null    float64\n",
            " 27  27      208 non-null    float64\n",
            " 28  28      208 non-null    float64\n",
            " 29  29      208 non-null    float64\n",
            " 30  30      208 non-null    float64\n",
            " 31  31      208 non-null    float64\n",
            " 32  32      208 non-null    float64\n",
            " 33  33      208 non-null    float64\n",
            " 34  34      208 non-null    float64\n",
            " 35  35      208 non-null    float64\n",
            " 36  36      208 non-null    float64\n",
            " 37  37      208 non-null    float64\n",
            " 38  38      208 non-null    float64\n",
            " 39  39      208 non-null    float64\n",
            " 40  40      208 non-null    float64\n",
            " 41  41      208 non-null    float64\n",
            " 42  42      208 non-null    float64\n",
            " 43  43      208 non-null    float64\n",
            " 44  44      208 non-null    float64\n",
            " 45  45      208 non-null    float64\n",
            " 46  46      208 non-null    float64\n",
            " 47  47      208 non-null    float64\n",
            " 48  48      208 non-null    float64\n",
            " 49  49      208 non-null    float64\n",
            " 50  50      208 non-null    float64\n",
            " 51  51      208 non-null    float64\n",
            " 52  52      208 non-null    float64\n",
            " 53  53      208 non-null    float64\n",
            " 54  54      208 non-null    float64\n",
            " 55  55      208 non-null    float64\n",
            " 56  56      208 non-null    float64\n",
            " 57  57      208 non-null    float64\n",
            " 58  58      208 non-null    float64\n",
            " 59  59      208 non-null    float64\n",
            " 60  60      208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n",
            "None\n",
            "       0       1       2       3       4   ...      56      57      58      59  60\n",
            "0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n",
            "1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n",
            "2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n",
            "3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n",
            "4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n",
            "\n",
            "[5 rows x 61 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbpBxNBfY-Z4"
      },
      "source": [
        "208개 샘플 , 60개 속성, 1 클래스 파악"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKxG-Z65ZHK0"
      },
      "source": [
        "# 판다스로 데이터 추출할 때 values 사용\r\n",
        "dataset = df.values\r\n",
        "x= dataset[:,0:60]\r\n",
        "y_obj= dataset[:,60]\r\n",
        "x= np.array(x).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "#x = df.iloc[:,:-1]\r\n",
        "#y = df.iloc[:,-1]\r\n",
        "# 문자열 숫자로 변환\r\n",
        "e= LabelEncoder()\r\n",
        "e.fit(y_obj)\r\n",
        "y = e.transform(y_obj)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbFDA_SDaKhj"
      },
      "source": [
        "###모델 설계 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsuMx5liaHKM",
        "outputId": "0fd7575e-4ce8-43b9-efc6-d8a4b28fd841"
      },
      "source": [
        "# 모델 설계\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(24,input_dim=60,activation='relu'))\r\n",
        "model.add(Dense(10,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "# 모델 컴파일\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# 모델 학습\r\n",
        "#x= np.array(x).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "model.fit(x,y,epochs=100,batch_size=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "42/42 [==============================] - 1s 1ms/step - loss: 0.6844 - accuracy: 0.5403\n",
            "Epoch 2/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.5863\n",
            "Epoch 3/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6651\n",
            "Epoch 4/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6914\n",
            "Epoch 5/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7494\n",
            "Epoch 6/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7378\n",
            "Epoch 7/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7755\n",
            "Epoch 8/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7959\n",
            "Epoch 9/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8033\n",
            "Epoch 10/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7902\n",
            "Epoch 11/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7564\n",
            "Epoch 12/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8085\n",
            "Epoch 13/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8293\n",
            "Epoch 14/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8097\n",
            "Epoch 15/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.7973\n",
            "Epoch 16/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4084 - accuracy: 0.8176\n",
            "Epoch 17/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7802\n",
            "Epoch 18/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8437\n",
            "Epoch 19/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8728\n",
            "Epoch 20/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8412\n",
            "Epoch 21/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8124\n",
            "Epoch 22/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8122\n",
            "Epoch 23/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8492\n",
            "Epoch 24/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8410\n",
            "Epoch 25/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8576\n",
            "Epoch 26/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8537\n",
            "Epoch 27/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.8914\n",
            "Epoch 28/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8581\n",
            "Epoch 29/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8298\n",
            "Epoch 30/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8859\n",
            "Epoch 31/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8947\n",
            "Epoch 32/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8664\n",
            "Epoch 33/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8691\n",
            "Epoch 34/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8587\n",
            "Epoch 35/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.8822\n",
            "Epoch 36/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.8988\n",
            "Epoch 37/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.9061\n",
            "Epoch 38/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.9092\n",
            "Epoch 39/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9271\n",
            "Epoch 40/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8724\n",
            "Epoch 41/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8909\n",
            "Epoch 42/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9259\n",
            "Epoch 43/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9112\n",
            "Epoch 44/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.8903\n",
            "Epoch 45/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9170\n",
            "Epoch 46/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9304\n",
            "Epoch 47/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9043\n",
            "Epoch 48/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9427\n",
            "Epoch 49/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.9272\n",
            "Epoch 50/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9309\n",
            "Epoch 51/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9049\n",
            "Epoch 52/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9447\n",
            "Epoch 53/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9074\n",
            "Epoch 54/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9362\n",
            "Epoch 55/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9329\n",
            "Epoch 56/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9206\n",
            "Epoch 57/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9530\n",
            "Epoch 58/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9227\n",
            "Epoch 59/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9207\n",
            "Epoch 60/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9219\n",
            "Epoch 61/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9482\n",
            "Epoch 62/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.8896\n",
            "Epoch 63/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9600\n",
            "Epoch 64/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9257\n",
            "Epoch 65/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9689\n",
            "Epoch 66/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9248\n",
            "Epoch 67/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9126\n",
            "Epoch 68/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9571\n",
            "Epoch 69/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9522\n",
            "Epoch 70/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9578\n",
            "Epoch 71/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9521\n",
            "Epoch 72/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9677\n",
            "Epoch 73/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9478\n",
            "Epoch 74/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9665\n",
            "Epoch 75/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9613\n",
            "Epoch 76/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9613\n",
            "Epoch 77/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9705\n",
            "Epoch 78/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9785\n",
            "Epoch 79/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9362\n",
            "Epoch 80/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9372\n",
            "Epoch 81/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9384\n",
            "Epoch 82/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9416\n",
            "Epoch 83/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9766\n",
            "Epoch 84/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9416\n",
            "Epoch 85/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9695\n",
            "Epoch 86/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9409\n",
            "Epoch 87/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9765\n",
            "Epoch 88/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9296\n",
            "Epoch 89/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9829\n",
            "Epoch 90/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9695\n",
            "Epoch 91/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9709\n",
            "Epoch 92/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9596\n",
            "Epoch 93/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9720\n",
            "Epoch 94/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9940\n",
            "Epoch 95/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9775\n",
            "Epoch 96/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9633\n",
            "Epoch 97/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9819\n",
            "Epoch 98/100\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9644\n",
            "Epoch 99/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9581\n",
            "Epoch 100/100\n",
            "42/42 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc792844908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkq9fWBSatu9",
        "outputId": "34b46acb-2c09-4f57-8050-57c2eaa1fd20"
      },
      "source": [
        "# 모델 평가\r\n",
        "print(model.evaluate(x,y)) # 책에서는 evaluate(x,y)[1] 이라 했는데 결과값 같음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9808\n",
            "[0.0813496857881546, 0.9807692170143127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv5s8eVUcvTv"
      },
      "source": [
        "### 결과: 오버피팅\r\n",
        "결과: 모델 정확도 99.04%  \r\n",
        "- 정확도가 너무 높다 => 과적합(overfitting) 예상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCpxl4FwOTVA"
      },
      "source": [
        "# 과적합 방지하기\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2x9KNSUOw5B"
      },
      "source": [
        "## 13.3 학습셋과 테스트셋\r\n",
        "과적합 인지 알 수 있도록 학습셋과 테스트셋을 나누어 학습시킨다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7LOpbk9Y9v_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRD_Wd3XO9YF"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split # 데이터를 학습셋과 테스트셋으로 나눔\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VVuE8YaPqWr",
        "outputId": "4e879a85-97d7-4b93-f94b-020f2c2494e2"
      },
      "source": [
        "# seed 값 설정\r\n",
        "seed=0\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(3)\r\n",
        "\r\n",
        "# 데이터 불러오기 \r\n",
        "df = pd.read_csv('../content/drive/MyDrive/모두의 딥러닝/deeplearning/dataset/sonar.csv',header=None)\r\n",
        "\r\n",
        "dataset = df.values\r\n",
        "x = dataset[:,0:60]\r\n",
        "y_obj = dataset[:,60]\r\n",
        "x= np.array(x).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "\r\n",
        "# 문자열 숫자 인코딩\r\n",
        "e =LabelEncoder()\r\n",
        "e.fit(y_obj)\r\n",
        "y = e.transform(y_obj)\r\n",
        "\r\n",
        "# 학습셋 테스트셋 구분 \r\n",
        "# random_state : 나눌 데이터를 랜덤하게 뽑는지 , 정수면 데이터는 seed\r\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state = seed) \r\n",
        "\r\n",
        "# 모델 설계\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(24,input_dim=60,activation='relu'))\r\n",
        "model.add(Dense(10,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "# 모델 컴파일\r\n",
        "model.compile(loss='mean_squared_error',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "# 여기선 평균제곱 오차를 사용했네\r\n",
        "\r\n",
        "# 모델 학습\r\n",
        "# 학습셋으로 학습\r\n",
        "#x_train = np.array(x_train).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "model.fit(x_train,y_train,epochs=130,batch_size=5)\r\n",
        "\r\n",
        "# 테스트셋에 모델 적용\r\n",
        "#x_test = np.array(x_test).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "print(model.evaluate(x_test,y_test)) # evaluate 의 결과값 [손실,정확도]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.4837\n",
            "Epoch 2/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.6013\n",
            "Epoch 3/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.6879\n",
            "Epoch 4/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.7034\n",
            "Epoch 5/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7643\n",
            "Epoch 6/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7571\n",
            "Epoch 7/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7188\n",
            "Epoch 8/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.8209\n",
            "Epoch 9/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.7874\n",
            "Epoch 10/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.8317\n",
            "Epoch 11/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.7945\n",
            "Epoch 12/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.8258\n",
            "Epoch 13/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.7864\n",
            "Epoch 14/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.7765\n",
            "Epoch 15/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.8089\n",
            "Epoch 16/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.8124\n",
            "Epoch 17/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.8276\n",
            "Epoch 18/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.8456\n",
            "Epoch 19/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.8069\n",
            "Epoch 20/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.8632\n",
            "Epoch 21/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.8905\n",
            "Epoch 22/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8588\n",
            "Epoch 23/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.8669\n",
            "Epoch 24/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8887\n",
            "Epoch 25/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.8494\n",
            "Epoch 26/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.8472\n",
            "Epoch 27/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.8730\n",
            "Epoch 28/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.8712\n",
            "Epoch 29/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.8897\n",
            "Epoch 30/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9166\n",
            "Epoch 31/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9062\n",
            "Epoch 32/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9318\n",
            "Epoch 33/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.8913\n",
            "Epoch 34/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9122\n",
            "Epoch 35/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.8897\n",
            "Epoch 36/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9093\n",
            "Epoch 37/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.8939\n",
            "Epoch 38/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9486\n",
            "Epoch 39/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9349\n",
            "Epoch 40/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9574\n",
            "Epoch 41/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9301\n",
            "Epoch 42/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9631\n",
            "Epoch 43/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9361\n",
            "Epoch 44/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9467\n",
            "Epoch 45/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9301\n",
            "Epoch 46/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9637\n",
            "Epoch 47/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9492\n",
            "Epoch 48/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9336\n",
            "Epoch 49/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9620\n",
            "Epoch 50/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9847\n",
            "Epoch 51/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9342\n",
            "Epoch 52/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9731\n",
            "Epoch 53/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9537\n",
            "Epoch 54/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9883\n",
            "Epoch 55/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9855\n",
            "Epoch 56/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9935\n",
            "Epoch 57/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9926\n",
            "Epoch 58/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9953\n",
            "Epoch 59/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9993\n",
            "Epoch 60/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9741\n",
            "Epoch 61/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9829\n",
            "Epoch 62/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9706\n",
            "Epoch 63/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9685\n",
            "Epoch 64/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 65/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9973\n",
            "Epoch 66/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9746\n",
            "Epoch 67/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 68/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 69/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 70/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 71/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9897\n",
            "Epoch 72/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 73/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9801\n",
            "Epoch 74/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 75/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 76/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 77/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 78/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 79/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 80/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9959\n",
            "Epoch 81/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 82/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 83/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 84/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 85/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 86/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 87/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 88/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 89/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 90/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 91/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 92/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 93/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 94/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 95/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 96/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 97/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 98/130\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 99/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 100/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 101/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 102/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 103/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 104/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 105/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 106/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 107/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 108/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 109/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 110/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 111/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 112/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 113/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 114/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 115/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 116/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 117/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 118/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 119/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 120/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 121/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 122/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 123/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 124/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 125/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 126/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 127/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 128/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 129/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 130/130\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.8571\n",
            "[0.1446620672941208, 0.8571428656578064]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H7cv7b4VBRx"
      },
      "source": [
        "### 테스트셋 결과\r\n",
        "- 테스트셋의 정확도 86% 로 과적합을 벗어남 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvYPWH-FM0ER"
      },
      "source": [
        "## 검증셋(validation set) 이용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-TiiZj3ZN9K"
      },
      "source": [
        "![validation.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlUdNn25W2sN"
      },
      "source": [
        "과정은 학습셋,테스트셋과 동일한데 모델 학습만 다름"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiOZhjiKXVvs"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split # 데이터를 학습셋과 테스트셋으로 나눔\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qpMG6mWPn82"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# seed 값 설정\r\n",
        "seed=0\r\n",
        "np.random.seed(seed)\r\n",
        "tf.random.set_seed(3)\r\n",
        "\r\n",
        "# 데이터 불러오기 \r\n",
        "df = pd.read_csv('../content/drive/MyDrive/모두의 딥러닝/deeplearning/dataset/sonar.csv',header=None)\r\n",
        "\r\n",
        "dataset = df.values\r\n",
        "x = dataset[:,0:60]\r\n",
        "y_obj = dataset[:,60]\r\n",
        "x= np.array(x).astype(np.float32)# x를 실수 넘파이로 변환 안해주면 에러가 남 이유는 모르겠음\r\n",
        "\r\n",
        "# 문자열 숫자 인코딩\r\n",
        "e =LabelEncoder()\r\n",
        "e.fit(y_obj)\r\n",
        "y = e.transform(y_obj)\r\n",
        "\r\n",
        "# 학습셋 테스트셋 구분 \r\n",
        "# random_state : 나눌 데이터를 랜덤하게 뽑는지 , 정수면 데이터는 seed\r\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state = seed) \r\n",
        "\r\n",
        "# 모델 설계\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(24,input_dim=60,activation='relu'))\r\n",
        "model.add(Dense(10,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "# 모델 컴파일\r\n",
        "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSsFzeSRXA6C"
      },
      "source": [
        "모델 학습 실행시에만 다름  \r\n",
        "validation_split= 를 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb8MT6mCXGC6",
        "outputId": "4208492e-5aee-4768-c1ba-b31e693b203e"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=200, batch_size=5, validation_split=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " 1/22 [>.............................] - ETA: 7s - loss: 0.2724 - accuracy: 0.2000WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc7906ed510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.2455 - accuracy: 0.5483 - val_loss: 0.2471 - val_accuracy: 0.5135\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.6345 - val_loss: 0.2409 - val_accuracy: 0.5405\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.6761 - val_loss: 0.2325 - val_accuracy: 0.6216\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.7279 - val_loss: 0.2293 - val_accuracy: 0.5946\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.6852 - val_loss: 0.2180 - val_accuracy: 0.6757\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.7311 - val_loss: 0.2132 - val_accuracy: 0.7027\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.7834 - val_loss: 0.2025 - val_accuracy: 0.7027\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.7448 - val_loss: 0.1972 - val_accuracy: 0.7297\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.7231 - val_loss: 0.1888 - val_accuracy: 0.7027\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.8085 - val_loss: 0.1818 - val_accuracy: 0.7297\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.7748 - val_loss: 0.1811 - val_accuracy: 0.7027\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.8147 - val_loss: 0.1761 - val_accuracy: 0.7568\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.8383 - val_loss: 0.1760 - val_accuracy: 0.7027\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.7433 - val_loss: 0.1653 - val_accuracy: 0.7568\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.8435 - val_loss: 0.1657 - val_accuracy: 0.7568\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.8533 - val_loss: 0.1627 - val_accuracy: 0.7568\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.8597 - val_loss: 0.1646 - val_accuracy: 0.7297\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.8642 - val_loss: 0.1591 - val_accuracy: 0.7297\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.8649 - val_loss: 0.1604 - val_accuracy: 0.7568\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.8795 - val_loss: 0.1561 - val_accuracy: 0.7568\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.8686 - val_loss: 0.1531 - val_accuracy: 0.7568\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.7978 - val_loss: 0.1701 - val_accuracy: 0.7027\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.8608 - val_loss: 0.1668 - val_accuracy: 0.7027\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.8025 - val_loss: 0.1545 - val_accuracy: 0.7838\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 0.8640 - val_loss: 0.1547 - val_accuracy: 0.7568\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.8938 - val_loss: 0.1541 - val_accuracy: 0.7838\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9147 - val_loss: 0.1538 - val_accuracy: 0.7838\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.8578 - val_loss: 0.1507 - val_accuracy: 0.7568\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9017 - val_loss: 0.1724 - val_accuracy: 0.7027\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.8955 - val_loss: 0.1526 - val_accuracy: 0.7838\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.8879 - val_loss: 0.1598 - val_accuracy: 0.7297\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.8546 - val_loss: 0.1520 - val_accuracy: 0.7838\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9299 - val_loss: 0.1520 - val_accuracy: 0.8108\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9348 - val_loss: 0.1497 - val_accuracy: 0.7838\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.8766 - val_loss: 0.1478 - val_accuracy: 0.8108\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9128 - val_loss: 0.1533 - val_accuracy: 0.7568\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.8905 - val_loss: 0.1831 - val_accuracy: 0.6757\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9033 - val_loss: 0.1467 - val_accuracy: 0.8108\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.8988 - val_loss: 0.1473 - val_accuracy: 0.8108\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9001 - val_loss: 0.1550 - val_accuracy: 0.7297\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9582 - val_loss: 0.1439 - val_accuracy: 0.7838\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9034 - val_loss: 0.1544 - val_accuracy: 0.7297\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9178 - val_loss: 0.1473 - val_accuracy: 0.8108\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9465 - val_loss: 0.1537 - val_accuracy: 0.7568\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9717 - val_loss: 0.1532 - val_accuracy: 0.7568\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9216 - val_loss: 0.1504 - val_accuracy: 0.7838\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9677 - val_loss: 0.1524 - val_accuracy: 0.7838\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.1450 - val_accuracy: 0.8108\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9289 - val_loss: 0.1537 - val_accuracy: 0.7568\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9601 - val_loss: 0.1531 - val_accuracy: 0.7568\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9689 - val_loss: 0.1561 - val_accuracy: 0.7297\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9439 - val_loss: 0.1439 - val_accuracy: 0.8378\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9469 - val_loss: 0.1655 - val_accuracy: 0.7297\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9550 - val_loss: 0.1512 - val_accuracy: 0.7568\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9804 - val_loss: 0.1398 - val_accuracy: 0.8378\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9696 - val_loss: 0.1421 - val_accuracy: 0.8378\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9750 - val_loss: 0.1412 - val_accuracy: 0.8378\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9313 - val_loss: 0.1565 - val_accuracy: 0.7297\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9659 - val_loss: 0.1479 - val_accuracy: 0.7838\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9376 - val_loss: 0.1840 - val_accuracy: 0.7027\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9423 - val_loss: 0.1434 - val_accuracy: 0.8108\n",
            "Epoch 62/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9729 - val_loss: 0.1454 - val_accuracy: 0.7297\n",
            "Epoch 63/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9400 - val_loss: 0.1815 - val_accuracy: 0.7027\n",
            "Epoch 64/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9420 - val_loss: 0.1308 - val_accuracy: 0.8378\n",
            "Epoch 65/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9491 - val_loss: 0.1469 - val_accuracy: 0.7297\n",
            "Epoch 66/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9584 - val_loss: 0.1537 - val_accuracy: 0.7297\n",
            "Epoch 67/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9591 - val_loss: 0.1427 - val_accuracy: 0.7838\n",
            "Epoch 68/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 0.1560 - val_accuracy: 0.7297\n",
            "Epoch 69/200\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9397 - val_loss: 0.1409 - val_accuracy: 0.7838\n",
            "Epoch 70/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.1557 - val_accuracy: 0.7297\n",
            "Epoch 71/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9575 - val_loss: 0.1499 - val_accuracy: 0.7297\n",
            "Epoch 72/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9799 - val_loss: 0.1588 - val_accuracy: 0.7297\n",
            "Epoch 73/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.1418 - val_accuracy: 0.7838\n",
            "Epoch 74/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 0.1565 - val_accuracy: 0.7297\n",
            "Epoch 75/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9953 - val_loss: 0.1434 - val_accuracy: 0.7838\n",
            "Epoch 76/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9900 - val_loss: 0.1486 - val_accuracy: 0.7838\n",
            "Epoch 77/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9900 - val_loss: 0.1483 - val_accuracy: 0.7297\n",
            "Epoch 78/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9706 - val_loss: 0.1578 - val_accuracy: 0.7297\n",
            "Epoch 79/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9820 - val_loss: 0.1334 - val_accuracy: 0.8108\n",
            "Epoch 80/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9829 - val_loss: 0.1250 - val_accuracy: 0.8649\n",
            "Epoch 81/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.1837 - val_accuracy: 0.7297\n",
            "Epoch 82/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9750 - val_loss: 0.1537 - val_accuracy: 0.7297\n",
            "Epoch 83/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9904 - val_loss: 0.1510 - val_accuracy: 0.7297\n",
            "Epoch 84/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9808 - val_loss: 0.1598 - val_accuracy: 0.7297\n",
            "Epoch 85/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9750 - val_loss: 0.1467 - val_accuracy: 0.7838\n",
            "Epoch 86/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9888 - val_loss: 0.1392 - val_accuracy: 0.7838\n",
            "Epoch 87/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.8108\n",
            "Epoch 88/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.1529 - val_accuracy: 0.7568\n",
            "Epoch 89/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.7838\n",
            "Epoch 90/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.8108\n",
            "Epoch 91/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.8378\n",
            "Epoch 92/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9762 - val_loss: 0.1425 - val_accuracy: 0.8108\n",
            "Epoch 93/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.8108\n",
            "Epoch 94/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9888 - val_loss: 0.1612 - val_accuracy: 0.7297\n",
            "Epoch 95/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.7297\n",
            "Epoch 96/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8378\n",
            "Epoch 97/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.7838\n",
            "Epoch 98/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.8378\n",
            "Epoch 99/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.8378\n",
            "Epoch 100/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.8108\n",
            "Epoch 101/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.7568\n",
            "Epoch 102/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.8378\n",
            "Epoch 103/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.8378\n",
            "Epoch 104/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.7838\n",
            "Epoch 105/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.8378\n",
            "Epoch 106/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.7838\n",
            "Epoch 107/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.8378\n",
            "Epoch 108/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.8378\n",
            "Epoch 109/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.8108\n",
            "Epoch 110/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.8378\n",
            "Epoch 111/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.8378\n",
            "Epoch 112/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.8378\n",
            "Epoch 113/200\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.7838\n",
            "Epoch 114/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.8378\n",
            "Epoch 115/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.8378\n",
            "Epoch 116/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.8378\n",
            "Epoch 117/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.7838\n",
            "Epoch 118/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.7568\n",
            "Epoch 119/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.8378\n",
            "Epoch 120/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.7838\n",
            "Epoch 121/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.8378\n",
            "Epoch 122/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.8108\n",
            "Epoch 123/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.8378\n",
            "Epoch 124/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.8108\n",
            "Epoch 125/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.8378\n",
            "Epoch 126/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.7838\n",
            "Epoch 127/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.8378\n",
            "Epoch 128/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.8378\n",
            "Epoch 129/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.8378\n",
            "Epoch 130/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.8378\n",
            "Epoch 131/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8378\n",
            "Epoch 132/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8378\n",
            "Epoch 133/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.8108\n",
            "Epoch 134/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.8108\n",
            "Epoch 135/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.8378\n",
            "Epoch 136/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.8378\n",
            "Epoch 137/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.8108\n",
            "Epoch 138/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.8378\n",
            "Epoch 139/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.8108\n",
            "Epoch 140/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.8378\n",
            "Epoch 141/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8378\n",
            "Epoch 142/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.8108\n",
            "Epoch 143/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.8378\n",
            "Epoch 144/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.8378\n",
            "Epoch 145/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.8378\n",
            "Epoch 146/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.8378\n",
            "Epoch 147/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.8378\n",
            "Epoch 148/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.8378\n",
            "Epoch 149/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.8108\n",
            "Epoch 150/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.8378\n",
            "Epoch 151/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.8378\n",
            "Epoch 152/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.8378\n",
            "Epoch 153/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.8378\n",
            "Epoch 154/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.8378\n",
            "Epoch 155/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8378\n",
            "Epoch 156/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.8108\n",
            "Epoch 157/200\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.8378\n",
            "Epoch 158/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.8378\n",
            "Epoch 159/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.8378\n",
            "Epoch 160/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.8378\n",
            "Epoch 161/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.8378\n",
            "Epoch 162/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.8378\n",
            "Epoch 163/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.8897e-04 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.8378\n",
            "Epoch 164/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.8378\n",
            "Epoch 165/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.8378\n",
            "Epoch 166/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.8378\n",
            "Epoch 167/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.8378\n",
            "Epoch 168/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.8378\n",
            "Epoch 169/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.1598e-04 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8378\n",
            "Epoch 170/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.9131e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.8378\n",
            "Epoch 171/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.3846e-04 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.8378\n",
            "Epoch 172/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 8.7901e-04 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.8378\n",
            "Epoch 173/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.3336e-04 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.8378\n",
            "Epoch 174/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.3798e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.8378\n",
            "Epoch 175/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 8.6812e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.8378\n",
            "Epoch 176/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9.4242e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.8378\n",
            "Epoch 177/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 7.1591e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.8378\n",
            "Epoch 178/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8.1731e-04 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.8378\n",
            "Epoch 179/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.4660e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.8378\n",
            "Epoch 180/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.8378\n",
            "Epoch 181/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 8.8046e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.8378\n",
            "Epoch 182/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 6.3636e-04 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.8378\n",
            "Epoch 183/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 8.7868e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.8378\n",
            "Epoch 184/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.3975e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.8378\n",
            "Epoch 185/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.4582e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.8378\n",
            "Epoch 186/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 6.0042e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.8378\n",
            "Epoch 187/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.9272e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.8378\n",
            "Epoch 188/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.5893e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.8378\n",
            "Epoch 189/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 6.5259e-04 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.8378\n",
            "Epoch 190/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 6.9909e-04 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.8378\n",
            "Epoch 191/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.4915e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.8649\n",
            "Epoch 192/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.4998e-04 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.8378\n",
            "Epoch 193/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 3.7647e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.8378\n",
            "Epoch 194/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 6.0075e-04 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.8378\n",
            "Epoch 195/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.4803e-04 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.8378\n",
            "Epoch 196/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 7.1870e-04 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.8649\n",
            "Epoch 197/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 4.5479e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.8378\n",
            "Epoch 198/200\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 3.8221e-04 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.8649\n",
            "Epoch 199/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 5.6472e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.8378\n",
            "Epoch 200/200\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 6.5526e-04 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc7916985c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAj_w5ZCXiQM"
      },
      "source": [
        "### 검증셋 학습 결과\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85wf5XsFXn0t",
        "outputId": "dd1276c2-ed72-45f3-e2e1-f769f26a4f7b"
      },
      "source": [
        "print(model.evaluate(x,y)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9279\n",
            "0.9278846383094788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjgIxTJsX15_"
      },
      "source": [
        "정확도 92% 로 살짝 오버피팅 방지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqvm4jTuV3R1"
      },
      "source": [
        "## 13.4 모델의 저장과 재사용\r\n",
        ": 학습시킨 모델을 저장하고 나중에 사용할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woXnKmSDWCgD"
      },
      "source": [
        "### 모델의 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKOeaKWoT61g"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "\r\n",
        "# 모델을 my_model.h5로 저장\r\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CE2mio3W6yw"
      },
      "source": [
        "### 현재 모델의 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB0QnZ28XC0t"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x7vx8KhXJE5"
      },
      "source": [
        "### 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifz4joSvXH9M",
        "outputId": "6b6dfd4e-eea4-4ac3-c5dd-e049960e968f"
      },
      "source": [
        "load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fc78f46ab70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "044ui_-xBuSK"
      },
      "source": [
        "## K겹 교차 검증(k_fold cross validation)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJkBjG6AXUSY",
        "outputId": "d453e7e5-1cb0-482b-affd-20e780bc59ee"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "n_fold =5 # 5겹 교차\r\n",
        "skf = StratifiedKFold(n_splits = n_fold ,shuffle=True, random_state = seed)\r\n",
        "\r\n",
        "# 정확도 리스트\r\n",
        "accuracy1=[]\r\n",
        "\r\n",
        "# 모델설정 및 실행\r\n",
        "for train,test in skf.split(x,y):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(24,input_dim=60,activation='relu'))\r\n",
        "  model.add(Dense(10,activation='relu'))\r\n",
        "  model.add(Dense(1,activation='sigmoid'))\r\n",
        "  \r\n",
        "  model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\r\n",
        "  model.fit(x[train],y[train],epochs=10,batch_size=5)\r\n",
        "\r\n",
        "  # n번째 정확도 배열에 추가하기\r\n",
        "  k_accuracy = model.evaluate(x[test],y[test])[1]\r\n",
        "  accuracy1.append(k_accuracy)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.4343\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.6273\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.7186\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.7416\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.7383\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.7425\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.7456\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7693\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7616\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.8284\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.6905\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.5617\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.5257\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.6090\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.6505\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.6968\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.6492\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.6691\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.7516\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.7180\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7508\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.7381\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.5696\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.6015\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.5959\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.6705\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.7399\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.6516\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.7041\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7429\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.8223\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.7535\n",
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc79130bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1903 - accuracy: 0.6190\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.5528\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.5553\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.6179\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.6199\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.6614\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.7231\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.7760\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.7307\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.7183\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7985\n",
            "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc79141fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.6829\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.4899\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.6473\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.6993\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.6993\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7610\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.7115\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7212\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7840\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7297\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.8429\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc791362620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1929 - accuracy: 0.7073\n",
            "[0.6904761791229248, 0.738095223903656, 0.6190476417541504, 0.6829268336296082, 0.707317054271698]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHZTwyrKcNA"
      },
      "source": [
        "### 교차검증 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50dYBpYOKa8f",
        "outputId": "208b0772-bc2d-4f68-db22-3568862f5191"
      },
      "source": [
        "print(accuracy1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6904761791229248, 0.738095223903656, 0.6190476417541504, 0.6829268336296082, 0.707317054271698]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}