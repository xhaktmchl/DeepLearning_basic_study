{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모두딥17.1장 NLP 토큰화.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8iaG_x6IjdC"
      },
      "source": [
        "## 문장을 단어로 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_MZLTV1zDdA"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqOXyQbIHKVO"
      },
      "source": [
        "### 문장 단어로 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D0dOuY9z3z8",
        "outputId": "8475d9e4-972d-4801-b413-062a56584fe4"
      },
      "source": [
        "text = '해보지 않으면 해낼 수 없다'\r\n",
        "result = text_to_word_sequence(text)\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['해보지', '않으면', '해낼', '수', '없다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ1Z87otHM1j"
      },
      "source": [
        "### Tokenizer에 대한 여러 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOAY6tEXHmDy"
      },
      "source": [
        "- token.word_counts : 단어의 개수\r\n",
        "- document_count : 문장의 개수\r\n",
        "- word_docs: 각 단어가 몇개의 문장에 있는지\r\n",
        "- word_index: 각 단어의 인덱스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjUAyX8X0AxF",
        "outputId": "40b7d543-1ad1-4b75-e549-8bda2449fe50"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "docs=['먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\r\n",
        "      '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\r\n",
        "      '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.']\r\n",
        "\r\n",
        "token = Tokenizer()\r\n",
        "token.fit_on_texts(docs)\r\n",
        "print(token.word_counts)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3cPHUwHUeK"
      },
      "source": [
        "### 문장의 개수 세기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGeqRvSM0-Ye",
        "outputId": "25e80d47-2fbc-4be5-8a10-8e0541a44b54"
      },
      "source": [
        "print(token.document_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upZE6F1oH7SA"
      },
      "source": [
        "### 각 단어가 포함된 문장의 개수 세기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqacPkGRHc3Y",
        "outputId": "24cf52e8-46a7-4aa8-fac3-6d67527b0730"
      },
      "source": [
        "print(token.word_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'나누어': 1, '먼저': 1, '각': 1, '단어를': 1, '텍스트의': 2, '토큰화합니다': 1, '인식됩니다': 1, '딥러닝에서': 2, '단어로': 1, '토큰화해야': 1, '있습니다': 1, '토큰화한': 1, '결과는': 1, '사용할': 1, '수': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIlNiWyWIRbg"
      },
      "source": [
        "### 각 단어의 인데스 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fgz4jwaIRJf",
        "outputId": "052416ec-f254-45b4-a7b6-e7b4614dffa5"
      },
      "source": [
        "print(token.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezqaI6YIXj_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}